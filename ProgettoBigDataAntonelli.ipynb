{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca6d370",
   "metadata": {},
   "source": [
    "###### Il progetto è visibile su github al seguente indirizzo: https://github.com/albianto97/bigdataFile.\n",
    "\n",
    "Il dataset analizzato (https://www.kaggle.com/datasets/shuhengmo/uber-nyc-forhire-vehicles-trip-data-2021), contiene informazioni sui viaggi fatti da varie licenze \"taxi\" nella città di New York.\n",
    "La grandezza totale del dataset è di 5 GB e contiene molte informazioni sui luoghi di partenza, arrivo, prezzo e varie tempistiche come l'orario e giorno di partenza e quelli d'arrivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd9066f-ba4d-4509-bb38-7b68db61974e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T14:56:30.622554Z",
     "iopub.status.idle": "2023-05-02T14:56:30.622827Z",
     "shell.execute_reply": "2023-05-02T14:56:30.622709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attach to a cluster to execute a cell."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"executorMemory\":\"6G\", \"numExecutors\":2, \"executorCores\":3, \"conf\":\n",
    "{\"spark.dynamicAllocation.enabled\": \"false\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e065b9b8-df3a-4be8-9511-ac3dff1b2c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T14:56:48.458056Z",
     "iopub.status.busy": "2023-05-02T14:56:48.457735Z",
     "iopub.status.idle": "2023-05-02T14:57:21.879765Z",
     "shell.execute_reply": "2023-05-02T14:57:21.878870Z",
     "shell.execute_reply.started": "2023-05-02T14:56:48.458030Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e308d9bfb184d428a06fcef77bd4385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1686342766862_0001</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-86.ec2.internal:20888/proxy/application_1686342766862_0001/\" class=\"emr-proxy-link\" emr-resource=\"j-1XZW2PZLD4QXI\n",
       "\" application-id=\"application_1686342766862_0001\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-16-18.ec2.internal:8042/node/containerlogs/container_1686342766862_0001_01_000001/livy\" >Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketname: String = unibo-bd-antonelli2023\n",
      "path_ml_tripdata: String = s3a://unibo-bd-antonelli2023/datasets/fhvhv_tripdata_2021-01.parquet\n",
      "path_ml_tripdata2: String = s3a://unibo-bd-antonelli2023/datasets/fhvhv_tripdata_2021-02.parquet\n",
      "res2: String = application_1686342766862_0001\n",
      "res4: String = SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/application_1686342766862_0001/\n"
     ]
    }
   ],
   "source": [
    "val bucketname = \"unibo-bd-antonelli2023\"\n",
    "val path_ml_tripdata =\n",
    "\"s3a://\"+bucketname+\"/datasets/fhvhv_tripdata_2021-01.parquet\"\n",
    "val path_ml_tripdata2 =\n",
    "\"s3a://\"+bucketname+\"/datasets/fhvhv_tripdata_2021-02.parquet\"\n",
    "\n",
    "sc.applicationId\n",
    "\n",
    "\"SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/\" + sc.applicationId + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d4e57",
   "metadata": {},
   "source": [
    "I dati sono presenti nel formato Parquet; dopo essere stati importati, tutti i job sono stati fatti dopo una successiva conversione in RDD. I dati sono raggruppati mensilmente, per un totale di 12 file Parquet. \n",
    "\n",
    "Importazione dei dati in formato Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f197b83d-b515-41c7-baf6-6799c2d06c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:09:24.941646Z",
     "iopub.status.busy": "2023-05-02T15:09:24.941321Z",
     "iopub.status.idle": "2023-05-02T15:09:36.258166Z",
     "shell.execute_reply": "2023-05-02T15:09:36.257233Z",
     "shell.execute_reply.started": "2023-05-02T15:09:24.941618Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfd8073d5ec46468eade5040c7becaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import spark.implicits._\n",
      "parquetFileDF: org.apache.spark.sql.DataFrame = [hvfhs_license_num: string, dispatching_base_num: string ... 22 more fields]\n",
      "parquetFileDF2: org.apache.spark.sql.DataFrame = [hvfhs_license_num: string, dispatching_base_num: string ... 22 more fields]\n"
     ]
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val parquetFileDF = spark.read.parquet(path_ml_tripdata)\n",
    "val parquetFileDF2 = spark.read.parquet(path_ml_tripdata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3603e",
   "metadata": {},
   "source": [
    "# Analisi dei campi del dataset\n",
    "* licenseClass: tipo stringa che rappresenta la licenza de taxi.\n",
    "\t* HV0002: Juno\n",
    "    * HV0003: Uber\n",
    "    * HV0004: Via\n",
    "    * HV0005: Lyft\n",
    "* license: tipo Stringa che rappresenta il numero del taxi.\n",
    "* request: tipo Timestamp che rappresenta la data/ora della richiesta del viaggio.\n",
    "* pickup: tipo Timestamp  che rappresenta la data/ora dell'inizio del viaggio.\n",
    "* dropoff: tipo Timestamp che rappresenta la data/ora della fine del viaggio.\n",
    "* distance: tipo Double che rappresenta la distanza totale in miglia percorsa dal taxi per questo viaggio.\n",
    "* startloc: tipo Long che rappresenta la zona di partenza del viaggio.\n",
    "* endloc: tipo Long che rappresenta la zona di arrivo del viaggio.\n",
    "* fare: tipo Double che rappresenta il prezzo del viaggio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f0c88e-57e1-4632-8efa-552c0006fd91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:28:01.761139Z",
     "iopub.status.busy": "2023-05-02T15:28:01.760829Z",
     "iopub.status.idle": "2023-05-02T15:28:02.514224Z",
     "shell.execute_reply": "2023-05-02T15:28:02.513439Z",
     "shell.execute_reply.started": "2023-05-02T15:28:01.761114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed92331f25e45cb8424991ff7d7528e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import java.sql.Timestamp\n",
      "defined class TaxiTrip\n",
      "defined object TaxiTrip\n",
      "warning: previously defined class TaxiTrip is not a companion to object TaxiTrip.\n",
      "Companions must be defined together; you may wish to use :paste mode for this.\n"
     ]
    }
   ],
   "source": [
    "import java.sql.Timestamp\n",
    "case class TaxiTrip(\n",
    "  licenseClass:String,\n",
    "  license:String,  \n",
    "  request:Timestamp,\n",
    "  pickup:Timestamp,\n",
    "  dropoff:Timestamp,\n",
    "  distance:Double,\n",
    "  startloc:Long,\n",
    "  endloc:Long,\n",
    "  //time:Long,\n",
    "  fare:Double,\n",
    ")\n",
    "\n",
    "object TaxiTrip {\n",
    "    def extract(row:org.apache.spark.sql.Row) = {\n",
    "        val licenseClass = row.getString(0)\n",
    "        val license = row.getString(1)\n",
    "        val request = row.getTimestamp(4)\n",
    "        val pickup = row.getTimestamp(5)\n",
    "        val dropoff = row.getTimestamp(6)\n",
    "        val distance = row.getDouble(9)\n",
    "        val startloc = row.getLong(7)\n",
    "        val endloc = row.getLong(8)\n",
    "        //val time = row.getLong(10)\n",
    "        val fare = row.getDouble(11)\n",
    "        \n",
    "        new TaxiTrip(licenseClass,license,request,pickup,dropoff,distance,startloc,endloc,fare)\n",
    "        \n",
    "\n",
    "        //new TaxiTrip(license,request,pickup,dropoff,startloc,endloc,distance,time,fare)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cee4a",
   "metadata": {},
   "source": [
    "La seguente funzione serve per convertire da formato timestamp a calendar, in modo da poter estrarre informazioni come giorno del mese, ora del giorno oppure giorno della settimana. <br>\n",
    "Si può notare che il dataset conteneva \"trip_time\" ossia il totale del tempo in secondi che i passeggeri hanno passato sul taxi durante il viaggio. <br>Ho preferito definire una funzione perchè sarebbe stata utile eventualmente per tutti i tempi importati dal dataset (request, pickup e dropoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49dafe9-6e00-4430-a651-81cc461d0b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:28:03.655889Z",
     "iopub.status.busy": "2023-05-02T15:28:03.655587Z",
     "iopub.status.idle": "2023-05-02T15:28:04.414267Z",
     "shell.execute_reply": "2023-05-02T15:28:04.413550Z",
     "shell.execute_reply.started": "2023-05-02T15:28:03.655864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21be43e0cd164c8fb0acec7ed373bd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import java.util.Calendar\n",
      "getDayTime: (time: Long)java.util.Calendar\n"
     ]
    }
   ],
   "source": [
    "import java.util.Calendar\n",
    "def getDayTime(time: Long): Calendar = {\n",
    "    var date:Calendar = Calendar.getInstance();\n",
    "    date.setTimeInMillis(time);\n",
    "    date\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57b9f6",
   "metadata": {},
   "source": [
    "# Creazione e caching del RDD a partire dal file Parquet.\n",
    "Caching per migliorare le prestazioni in vista di futuri utilizzi.<br>Essendoci due executor con tre core ciascuno, il numero totale di core è sei. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fc0cb6-743c-417b-aedd-4d485fcd83ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:28:04.415655Z",
     "iopub.status.busy": "2023-05-02T15:28:04.415418Z",
     "iopub.status.idle": "2023-05-02T15:28:05.670742Z",
     "shell.execute_reply": "2023-05-02T15:28:05.669880Z",
     "shell.execute_reply.started": "2023-05-02T15:28:04.415631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cbb80f8d7b40249a6a7f41ad5f03f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[9] at rdd at <console>:28\n",
      "data_rdd2: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[15] at rdd at <console>:28\n",
      "rddTaxiTrip: org.apache.spark.rdd.RDD[TaxiTrip] = MapPartitionsRDD[16] at map at <console>:29\n",
      "rddTaxiTrip2: org.apache.spark.rdd.RDD[TaxiTrip] = MapPartitionsRDD[17] at map at <console>:29\n"
     ]
    }
   ],
   "source": [
    "val data_rdd = parquetFileDF.rdd\n",
    "val data_rdd2 = parquetFileDF2.rdd\n",
    "val rddTaxiTrip = data_rdd.map(TaxiTrip.extract)\n",
    "val rddTaxiTrip2 = data_rdd2.map(TaxiTrip.extract)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22209e",
   "metadata": {},
   "source": [
    "# File di input\n",
    "Per tutte le seguenti query verranno utilizzati due file, i quali verranno uniti successivamente attraverso una union: il primo contenente i dati per il mese di gennaio 2021, il secondo contente i dati di febbraio 2021.\n",
    "<br>Avendo caricato tutti i file nella cartella è possibile fare confronti anche su mesi diversi, ed avendo Kaggle anche i dataset di anni precedenti la stessa analisi può essere effettutata anche su anni differenti. (Attenzione ad eventuali campi mancanti in dataset di anni precedenti). \n",
    "<br>La grandezza di input è di circa 380/390 MB a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02dcf96",
   "metadata": {},
   "source": [
    "### Numero totale di record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23280221",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddTaxiTrip.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e63f75",
   "metadata": {},
   "source": [
    "### Numero totale di zone di arrivo diverse\n",
    "Nota: Lo stesso numero sono quelle di partenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6de18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:28:05.672251Z",
     "iopub.status.busy": "2023-05-02T15:28:05.672000Z",
     "iopub.status.idle": "2023-05-02T15:28:33.006426Z",
     "shell.execute_reply": "2023-05-02T15:28:33.005594Z",
     "shell.execute_reply.started": "2023-05-02T15:28:05.672225Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddTaxiTrip.map(x => x.endloc).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161b829",
   "metadata": {},
   "source": [
    "### Stampa delle classi di licenza \n",
    "Nel caso ne mancasse qualcuna significa che non è presente nel periodo di tempo considerato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32449cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddTaxiTrip.map(x => x.licenseClass).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4c891",
   "metadata": {},
   "source": [
    "###  Viaggi più lunghi in termine di KM, in relazione con la durata del viaggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f432b96-c256-4e46-833b-d019f14bac51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:29:59.846745Z",
     "iopub.status.busy": "2023-05-02T15:29:59.846439Z",
     "iopub.status.idle": "2023-05-02T15:30:00.596610Z",
     "shell.execute_reply": "2023-05-02T15:30:00.595811Z",
     "shell.execute_reply.started": "2023-05-02T15:29:59.846720Z"
    }
   },
   "outputs": [],
   "source": [
    "val query1 = rddTaxiTrip.map(x => (x.distance, (x.dropoff.getTime() - x.pickup.getTime())/(60*1000)))\n",
    "val query1802 = rddTaxiTrip2.map(x => (x.distance, (x.dropoff.getTime() - x.pickup.getTime())/(60*1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6dac2-9be8-439f-8ea5-2b7e26102467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:30:22.561188Z",
     "iopub.status.busy": "2023-05-02T15:30:22.560881Z",
     "iopub.status.idle": "2023-05-02T15:30:23.309643Z",
     "shell.execute_reply": "2023-05-02T15:30:23.308883Z",
     "shell.execute_reply.started": "2023-05-02T15:30:22.561162Z"
    }
   },
   "outputs": [],
   "source": [
    "val query1union = query1.union(query1802).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2585a-6fbc-45a2-94a9-d0ced2056e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:30:36.614895Z",
     "iopub.status.busy": "2023-05-02T15:30:36.614554Z",
     "iopub.status.idle": "2023-05-02T15:31:25.999880Z",
     "shell.execute_reply": "2023-05-02T15:31:25.999158Z",
     "shell.execute_reply.started": "2023-05-02T15:30:36.614865Z"
    }
   },
   "outputs": [],
   "source": [
    "query1union.sortByKey(false).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575316e8",
   "metadata": {},
   "source": [
    "### Numero di viaggi effettuati da ciascun conducente in base all'ora di inizio del viaggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f21cc2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6433657123421db63040825d5e80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Array[(Int, Int)] = Array((4,844296), (0,934327), (8,1182479), (1,886481), (9,1076083), (5,953156), (6,1082789), (10,1061788), (2,870515), (11,987859), (3,848995), (7,1179700))\n"
     ]
    }
   ],
   "source": [
    "val result = rddTaxiTrip.map(x => ((getDayTime(x.pickup.getTime()).get(Calendar.HOUR)), 1)).reduceByKey(_ + _).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d022c06",
   "metadata": {},
   "source": [
    "### Viaggi piu costosi in termine di KM\n",
    "Aggiunto un filtro sulla distanza minima. Questo comporterà solo la stampa dei viaggi più costosi visto che ci si aspetta che l'andamento sia proporzionale tra distanza e costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffa170",
   "metadata": {},
   "outputs": [],
   "source": [
    "val query2 = rddTaxiTrip.filter(_.distance > 20).map(x => (x.fare, ((x.dropoff.getTime() - x.pickup.getTime())/(60*1000))))\n",
    "val query2802 = rddTaxiTrip2.filter(_.distance > 20).map(x => (x.fare, ((x.dropoff.getTime() - x.pickup.getTime())/(60*1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "val query2union = query2.union(query2802).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ae2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2union.sortByKey(false).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e610e",
   "metadata": {},
   "source": [
    "### Distanza totale percorsa da ciascuna licenza di taxi in ciascuna zona di partenza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "val totalDistanceByLicenseAndStartLoc = rddTaxiTrip.map(x => ((x.license, x.startloc), x.distance)).reduceByKey((x, y) => x + y).take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09001a",
   "metadata": {},
   "source": [
    "### Tempo di viaggio medio, in base alla zona di partenza\n",
    "Il codice esegue le seguenti operazioni:\n",
    "* Viene eseguita una map per estrarre la zona di partenza e il tempo di viaggio;\n",
    "* Successivamente viene fatta un aggregazione in base alla chiave per andare a calcolare la somma dei tempi e il conteggio dei viaggi;\n",
    "\n",
    "Queste azioni sono state svolte per entrambi gli RDD dei mesi.\n",
    "\n",
    "* Viene eseguita una union per raggruppare i due valori;\n",
    "\n",
    "Il risultato finale che si sta cercando è quello di vedere per ogni zona quanto è il tempo medio di viaggio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8623d60-2dde-4ce2-b3ca-f2c33f7f8b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T15:42:16.949801Z",
     "iopub.status.busy": "2023-05-02T15:42:16.949501Z",
     "iopub.status.idle": "2023-05-02T15:42:17.705139Z",
     "shell.execute_reply": "2023-05-02T15:42:17.704291Z",
     "shell.execute_reply.started": "2023-05-02T15:42:16.949775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val query3 = rddTaxiTrip.map(x => (x.startloc, (x.dropoff.getTime() - x.pickup.getTime())/(60*1000))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v,a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2))\n",
    "val query31 = rddTaxiTrip2.map(x => (x.startloc, (x.dropoff.getTime() - x.pickup.getTime())/(60*1000))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v,a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2))\n",
    "val query3union = query3.union(query31).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cff56",
   "metadata": {},
   "source": [
    "##### Risultato raggruppato per vedere la differenza tra i due mesi rispetto alla zona di partenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val q = query3union.map({case(k,v) => (k,v._1/v._2)}).groupByKey().map({case(k,v) => (v,k)}).sortByKey(false).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46913a6",
   "metadata": {},
   "source": [
    "### In media quanti viaggi fa ciascuna licenza\n",
    "\n",
    "Inizialmente, la funzione \"map\" viene utilizzata per estrarre le informazioni relative al numero di licenze e al numero di viaggi effettuati. Infine, la funzione \"aggregate\" viene utilizzata per calcolare la somma totale dei viaggi e il numero totale di licenze. Infine, viene calcolata la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val query4 = rddTaxiTrip.map(x => (x.license,1)).\n",
    "reduceByKey(_+_).\n",
    "aggregate((0,0))((a,v)=>(a._1+v._2, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2))\n",
    "\"Media: \" + (query4._1/query4._2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bb709",
   "metadata": {},
   "source": [
    "### Numero di viaggi effettuati per ogni combinazione di ora di inizio del viaggio e zona di arrivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6393b9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ea7303de38455a9ecf7543e2acd3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTrip: Array[(Int, (Int, Long))] = Array((37314,(7,265)), (36103,(8,265)), (34085,(10,265)), (33517,(6,265)), (33365,(9,265)), (31528,(11,265)), (29066,(5,265)), (29061,(0,265)), (26894,(1,265)), (26685,(2,265)), (25943,(4,265)), (25941,(3,265)), (20991,(7,61)), (20621,(8,61)), (20286,(10,61)), (19643,(9,61)), (19287,(6,61)), (19081,(11,61)), (18057,(0,61)), (17079,(5,61)), (17069,(8,76)), (16668,(7,76)), (16421,(1,61)), (15959,(2,61)), (15618,(4,61)), (15611,(3,61)), (15520,(11,76)), (15490,(9,76)), (15273,(6,76)), (14947,(10,76)), (14935,(2,76)), (14852,(3,76)), (14849,(5,76)), (14367,(7,37)), (14302,(7,42)), (14289,(8,42)), (14129,(0,76)), (14023,(10,37)), (13843,(5,132)), (13819,(8,37)), (13782,(4,76)), (13693,(1,76)), (13310,(8,244)), (13193,(9,42)), (13146,(9,37)), (13115,(6,244))...\n"
     ]
    }
   ],
   "source": [
    "val NTrip = rddTaxiTrip.map(x => ((getDayTime(x.pickup.getTime()).get(Calendar.HOUR), x.endloc), 1)).\n",
    "reduceByKey(_ + _).\n",
    "map { case ((hour, endloc), count) => (count, (hour, endloc)) }.\n",
    "sortByKey(false).\n",
    "collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e4d4e",
   "metadata": {},
   "source": [
    "###  Classe di licenza che fa piu viaggi, con la presenza anche della tariffa cliente\n",
    "\n",
    "Questo codice stampa i risultati delle classi di licenze che fa più viaggi in relazione anche al guadagno. In particolare, il codice mappa ogni elemento in una tupla in cui la chiave è la licenza, contenente il guadagno e il numero di viaggi di ogni licenza. Poi, i dati vengono aggregati tramite la funzione reduceByKey che somma i valori associati alla stessa chiave. Successivamente, il risultato viene mappato in una tupla contenente il nome della licenza, il guadagno totale e il numero di viaggi totali e viene ordinato in modo decrescente in base al guadagno. Infine, vengono stampati gli elementi della lista di risultati ottenuti dalla funzione collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9563e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val query5 = rddTaxiTrip.map(x => (x.licenseClass,(x.fare,1))).\n",
    "reduceByKey((t1,t2) => (t1._1+t2._1, t1._2+t2._2)).\n",
    "map(v => (v._1,v._2._1, v._2._2)).\n",
    "sortBy(_._2,false).\n",
    "collect().foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771eb861",
   "metadata": {},
   "source": [
    "### Licenza che fa piu viaggi, con la presenza anche della tariffa cliente\n",
    "\n",
    "Qui viene eseguita una replica della query precedente, basandosi su ogni singola licenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ff7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "val query6 = rddTaxiTrip.map(x => (x.license,(x.fare,1))).\n",
    "reduceByKey((t1,t2) => (t1._1+t2._1, t1._2+t2._2)).\n",
    "map(v => (v._1,v._2._1, v._2._2)).\n",
    "sortBy(_._2,false).\n",
    "collect().foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a63b9a",
   "metadata": {},
   "source": [
    "### Licenza di taxi con il prezzo medio del viaggio più alto per ciascuna classe di licenza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val avgFareByLicenseClass = rddTaxiTrip.map(x => (x.licenseClass, x.fare)).groupByKey().\n",
    "mapValues(fares => fares.sum / fares.size).reduceByKey((fare1, fare2) => if (fare1 > fare2) fare1 else fare2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgFareByLicenseClass.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f21e51",
   "metadata": {},
   "source": [
    "### Distanza media percorsa dai taxi in un singolo viaggio, in relazione alla zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321f1ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e58f7702b648f1be8444ba18622abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query8: org.apache.spark.rdd.RDD[(Long, (Double, Double))] = ShuffledRDD[20] at aggregateByKey at <console>:29\n",
      "query81: org.apache.spark.rdd.RDD[(Long, (Double, Double))] = ShuffledRDD[23] at aggregateByKey at <console>:29\n"
     ]
    }
   ],
   "source": [
    "val query8 = rddTaxiTrip.filter(_.distance < 100).map(x => (x.startloc,x.distance)).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v,a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2))\n",
    "val query81 = rddTaxiTrip2.filter(_.distance < 100).map(x => (x.startloc,x.distance)).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v,a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71ade4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33547fba30964e63837ba4675917743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query8union: org.apache.spark.rdd.RDD[(Long, (Double, Double))] = PartitionerAwareUnionRDD[24] at union at <console>:29\n"
     ]
    }
   ],
   "source": [
    "val query8union = query8.union(query81).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b415fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4106309846d4487d96213195509aeb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q8: Array[(Double, Long)] = Array((20.136333333333326,1), (19.978372093023246,1), (15.583862644195618,132), (14.864652072083206,132), (11.889173913043477,2), (10.915017273061434,138), (10.765875894988065,27), (10.74933302682418,138), (10.515,199), (10.507823529411766,110))\n"
     ]
    }
   ],
   "source": [
    "val q8 = query8union.map({case(k,v) => (k,v._1/v._2)}).map({case(k,v) => (v,k)}).sortByKey(false).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebf377",
   "metadata": {},
   "source": [
    "Il codice:\n",
    "* Crea una sessione Spark utilizzando SparkSession.builder.getOrCreate(). Questo garantisce che venga creata una nuova sessione Spark o che venga utilizzata una sessione esistente, se disponibile.\n",
    "* Crea un array di oggetti Row utilizzando i dati ottenuti dalla query q8. Ogni oggetto Row corrisponde a una riga del DataFrame e contiene i valori delle colonne.\n",
    "* Crea il DataFrame utilizzando il metodo createDataFrame di SparkSession. Viene passato l'array di righe e lo schema precedentemente definito. Il DataFrame rappresenta la tabella con le righe e le colonne corrispondenti ai dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe33d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c16be935a464b9b9a411d7b0a0a6e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.sql.{SparkSession, SaveMode}\n",
      "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6d251e2d\n",
      "df: org.apache.spark.sql.DataFrame = [Value: double, Key: bigint]\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.{SparkSession, SaveMode}\n",
    "\n",
    "// Crea la sessione Spark\n",
    "val spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "// Converte q8 in un DataFrame\n",
    "val df = spark.createDataFrame(q8).toDF(\"Value\", \"Key\")\n",
    "\n",
    "// Salva il DataFrame come file CSV\n",
    "df.write.format(\"csv\").mode(SaveMode.Overwrite).option(\"header\", \"true\").save(\"s3a://\" + bucketname + \"/datasets/project/output/avgDistance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047fd11",
   "metadata": {},
   "source": [
    "### Zona di arrivo più comune per ciascuna licenza di taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc69f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "val mostCommonEndLocByLicense = rddTaxiTrip.map(x => ((x.license, x.endloc), 1)).reduceByKey(_ + _)\n",
    ".map { case ((license, endloc), count) => (license, (endloc, count)) }.groupByKey().mapValues { locs => locs.maxBy(_._2)._1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostCommonEndLocByLicense.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SaveMode\n",
    "val mostCommonEndLocDF = mostCommonEndLocByLicense.toDF(\"license\", \"endloc\")\n",
    "mostCommonEndLocDF.write.format(\"csv\").mode(SaveMode.Overwrite).save(\"s3a://\"+bucketname+\"/datasets/project/output/MaxLoc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd8d3e",
   "metadata": {},
   "source": [
    "### Analisi sul guadagno medio di ogni singolo viaggio per ogni giorno\n",
    "Il codice ha lo scopo di calcolare il guadagno medio di ogni classe di licenza in base al giorno in cui si è svolto il viaggio. Il risultato è stato poi salvato in un file CSV.<br>\n",
    "Sono state eseguite le seguenti operazioni:\n",
    "* Viene eseguito creato un RDD (avgFareByDay) che associa a ciascuna coppia (classe di licenza, Giorno) una tupla contenente la somma del guadagno e il numero di viaggi durante il giorno.\n",
    "* Viene quindi eseguita una riduzione per chiave (reduceByKey) per aggregare i dati raggruppati per classe di licenza e giorno.\n",
    "* Successivamente, viene eseguita una mappatura (mapValues) per calcolare il guadagno medio di ogni viaggio per ogni giorno.\n",
    "* In seguito, viene eseguita una mappatura (map) per riorganizzare i dati e raggrupparli per classe di licenza.\n",
    "* Vengono poi eseguite ulteriori operazioni di trasformazione (flatMap e coalesce) per preparare i dati per il salvataggio su file CSV.\n",
    "* Infine, viene convertito l'RDD in un DataFrame e salvato in un file CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72fe3eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af197a0848fd43bdb7c3395f64bed862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgFareByDay: org.apache.spark.rdd.RDD[(String, Double, Int)] = MapPartitionsRDD[29] at map at <console>:51\n"
     ]
    }
   ],
   "source": [
    "val avgFareByDay = rddTaxiTrip.map(x => ((x.licenseClass, getDayTime(x.pickup.getTime()).get(Calendar.DAY_OF_WEEK)), (x.fare, 1))).\n",
    "  reduceByKey((accum, value) => (accum._1 + value._1, accum._2 + value._2)).\n",
    "  mapValues(sumCount => sumCount._1 / sumCount._2).\n",
    "  map(item => (item._1._1, item._2, item._1._2))\n",
    "  //collect() //(licenza,avg,giorno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "155806d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b161776aca4c44f0b9ebe92ea374d3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgFareByLicense: org.apache.spark.rdd.RDD[(String, Iterable[(Double, Int)])] = MapPartitionsRDD[32] at mapValues at <console>:49\n"
     ]
    }
   ],
   "source": [
    "// Raggruppo per licenza\n",
    "val avgFareByLicense = avgFareByDay.groupBy(_._1).\n",
    "  mapValues(_.map(item => (item._2, item._3)))//.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f89db2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9cf0228a2848bcbec3dec620c62679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgFareByLicenseAndDay: org.apache.spark.rdd.RDD[((String, Int), Double)] = CoalescedRDD[34] at coalesce at <console>:52\n"
     ]
    }
   ],
   "source": [
    "//flatmap con chiave prodotto e anno\n",
    "val avgFareByLicenseAndDay = avgFareByLicense.flatMap { \n",
    "    case (license, dayFare) => dayFare.map { \n",
    "        case (avgFare, day) => ((license, day),avgFare)\n",
    "  }\n",
    "}.coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d555a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3791f62e754988b81d1e96043be9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.sql.SaveMode\n",
      "df: org.apache.spark.sql.DataFrame = [_1: string, _2: int ... 1 more field]\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.SaveMode\n",
    "// Conversione in DataFrame con stringa\n",
    "val df = avgFareByLicenseAndDay.map{case ((license, day), avgFare) => (license,day,avgFare)}.toDF()\n",
    "\n",
    "// Salvataggio su file CSV\n",
    "df.write.format(\"csv\").mode(SaveMode.Overwrite).save(\"s3a://\"+bucketname+\"/datasets/project/output/avgFare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71472ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
